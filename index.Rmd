---
title: "Practical Machine Learning Course Project"
author: "Matthew Jorden"
date: "5/20/2017"
output: html_document
---

The purpose of this exercise is to predict quality of exercise based on given classes from fitness devices. A testing set (with class labels) and a training set has been provided. From the training set, I intend to create a model which can correctly predict the classes on the testing set.

First things first, I need to load the packages `caret`, `readr`, `rpart`, `ggplot2` and `randomForest` as well as set a seed for reproducibility.

```{r setup, warning=FALSE, message=FALSE}
library(caret)
library(readr)
library(rpart)
library(ggplot2)
library(randomForest)
set.seed(4345)
```

## Loading & Cleaning Data

Both data sets were downloaded from the URL provided by the Coursera course. I download both and read them into a train & a test set.

There are many variables in the data, most of which may not be useful or may not contain complete records. To account for this, I remove columns with NA values. I accomplish this by creating a list of columns that contain NA values, and remove these columns from both the training & testing data sets.

Next, I need to separate the training data itself into a training and testing set for validaton & checking in-sample and out of sample errors. I am placing 70% of the data into the training set, and retaining 30% to test the models.

```{r cars, message=FALSE, warning=FALSE}
train <- read_csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test <- read_csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")

NAcolumns <- colMeans(is.na(train))
train <- train[, !NAcolumns]
train <- train[, -c(1:5)]
test <- test[, !NAcolumns]
test <- test[, -c(1:5)]

inTrain <- createDataPartition(y = train$classe, p = 0.7, list = FALSE)
training <- train[inTrain,]
testing <- train[-inTrain,]
```

##Creating Models

I am going to run two models, one using the rpart method and one using random forest. Fair warning if you run this at home: The rpart runs quickly, but the random forest method takes significant time & resources to complete.

###RPart Model

The RPart model is generated by calling the `caret` command `train()`. 

```{r Rpartmodel}
modRPart <- train(classe ~ ., data = training, method = "rpart")
#print(modRPart$finalModel)
plot(modRPart$finalModel, main = "RPart Decision Tree")
text(modRPart$finalModel)
```

I then predict values for both the training & testing data sets. 

```{r Rpart}
predRpart <- predict(modRPart, training)
predRpart2 <- predict(modRPart, testing)
```

Lets first take a look at the results from the predicted classed on the training set.

```{r Rpart1}
confmax <- confusionMatrix(training$classe, predRpart)
print(confmax$table)
print(confmax$overall)
```

The rpart model performed well for predicting Classes A & B, but does not appear to be able to distinguish between classes C, D & E.

The overall accuracy for the RPart model is `r confmax$overall[1]`.

```{r Rpart2}

confmax2 <- confusionMatrix(testing$classe, predRpart2)
print(confmax2$table)
print(confmax2$overall)
```

The rpart model shows the same weakness on the testing data as it did the training data - it can easily distinguish between Classes A & B, but cannot distinguish between classes C, D & E. The overall accuracy for the RPart model is `r confmax2$overall[1]`.

* The in sample error rate is `r (1 - confmax$overall[1]) * 100`%

* The out of sample error rate is `r 1 - confmax2$overall[1] * 100`%

Given that our accuracies here are `r confmax$overall[1]` and `r confmax2$overall[1]` are slightly above 0.5, I propose we abandon the RPart model. Instead of a single tree like rpart creates, lets move to a random forest approach.


###Random Forest

Since Rpart did not give us a satisfactory solution, I will try a random forest model. I warn users that this takes some time & computational resources to complete.

```{r randfor}
modRF <- train(classe ~ ., data= training, method="rf", ntree = 50)
plot(modRF$finalModel, main = "Random Forest Accuracy")
```

The above plot shows accuracy as additional trees are added to the forest. It appears that a 50 tree model is eliminating most error.

Lets also take a look at which variables are considered important predictors:

```{r varimp}
varImp(modRF)
```

The relevant predictors are quite similar to the previous tree created with `rpart`. The advantage with the `random forest` approach is the multiple trees averaging towards an outcome.

```{r randforpred1}
predRF1 <- predict(modRF, training)
confmax3 <- confusionMatrix(training$classe, predRF1)
print(confmax3$table)
```

The table shows that within our training data, the model has correctly predicted every single point. The resulting model accuracy is `r confmax3$overall[1]`

```{r randforpred2}
predRF2 <- predict(modRF, testing)
confmax4 <- confusionMatrix(testing$classe, predRF2)
print(confmax4$table)
```

The table shows that within our training data, the model has correctly predicted most points. The resulting model accuracy is `r confmax4$overall[1]`

* The in sample error rate is `r (1 - confmax3$overall[1]) * 100`%

* The out of sample error rate is `r (1 - confmax4$overall[1]) * 100`%

Comparing the Random Forest accuracies of `r confmax3$overall[1]` / `r confmax4$overall[1]` to the RPart accuracies of `r confmax$overall[1]` / `r confmax2$overall[1]`, we can clearly see that Random Forest is the correct choice for the model.

## Final Prediction

Now that I have chosen the final model, I just need to apply it to the test data and determine final predicted classes.

```{r finalpred}
finalpred <- predict(modRF, test)
```

I am not showing the results, but when I completed the Coursera quiz I received a grade of 100%. The models accuracy is 100%, or close to it.
